{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zhusuan as zs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from zhusuan.variational import svgd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/zhusuan-dev/zhusuan/distributions/univariate.py:84: FutureWarning: Normal: The order of arguments logstd/std will change to std/logstd in the coming version.\n",
      "  \"to std/logstd in the coming version.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iter 49 Acc.Rate 0.6430097818374634 RMSE 3.1014029979705811\n",
      " Iter 99 Acc.Rate 0.8837264776229858 RMSE 0.58232194185256966\n",
      " Iter 149 Acc.Rate 0.5906104445457458 RMSE 0.106316871941089633\n",
      " Iter 199 Acc.Rate 0.21730247139930725 RMSE 0.10014601796865463\n"
     ]
    }
   ],
   "source": [
    "n_covariates = 13\n",
    "\n",
    "w_true = np.random.normal(size=[n_covariates, 1])\n",
    "b_true = np.random.normal() * 0.5\n",
    "X = np.random.uniform(-2, 2, size=[500, n_covariates])\n",
    "Y = np.squeeze((X) @ w_true) + b_true + np.random.normal(size=[500]) * 0.1\n",
    "# Y_prob = 1 / (1 + np.exp(-Y_logits))\n",
    "# Y = np.zeros((X.shape[0], ), dtype=np.int32)\n",
    "# Y[np.random.uniform(0, 1, size=[X.shape[0]]) < Y_prob] = 1\n",
    "\n",
    "@zs.reuse('linear_reg')\n",
    "def linear_regression(inp, observed):\n",
    "    with zs.BayesianNet(observed) as model:\n",
    "        w = zs.Normal(\n",
    "            'w', \n",
    "            mean=tf.zeros([n_covariates, 1]),\n",
    "            std=np.float32(1),\n",
    "            group_ndims=2)\n",
    "        b = zs.Normal(\n",
    "            'b', \n",
    "            mean=np.float32(0),\n",
    "            std=np.float32(1))\n",
    "        n_particles = tf.shape(w.tensor)[0]  # TODO: this assumes rank(w)==3. Does this hold when n_particles=1?\n",
    "        inp = tf.tile(tf.expand_dims(inp, 0), [n_particles, 1, 1])\n",
    "        # print(tf.squeeze(inp @ w, axis=-1).shape, b.tensor.shape)\n",
    "        mean = tf.squeeze(inp @ w, axis=-1) + tf.expand_dims(b, 1) # [n_particles, n_batch]\n",
    "        # print(logits.shape)\n",
    "        var_out = zs.Normal('var_out', mean=np.float32(0.1), std=np.float32(1))\n",
    "        std = tf.expand_dims(tf.nn.softplus(var_out), 1)\n",
    "        out = zs.Normal('out', mean, std, group_ndims=1) \n",
    "    return model\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, [None, n_covariates])\n",
    "y_ph = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "def log_joint(observed):\n",
    "    model = linear_regression(x_ph, observed)\n",
    "    ret = tf.add_n(model.local_log_prob(['w', 'b', 'var_out', 'out']))\n",
    "    return ret\n",
    "\n",
    "hmc = zs.HMC(step_size=1e-2, n_leapfrogs=20, adapt_step_size=True,\n",
    "             target_acceptance_rate=0.6)\n",
    "n_chain = 10\n",
    "w_hmc = tf.Variable(tf.zeros([n_chain, n_covariates, 1]), name='w_hmc')\n",
    "b_hmc = tf.Variable(tf.zeros([n_chain]), name='b_hmc')\n",
    "var_out_hmc = tf.Variable(tf.zeros([n_chain]), name='var_out')\n",
    "sample_op, hmc_info = hmc.sample(\n",
    "    log_joint, observed={'out': y_ph}, \n",
    "    latent={'w': w_hmc, 'b': b_hmc, 'var_out': var_out_hmc})\n",
    "\n",
    "model = linear_regression(x_ph, {\n",
    "    'out': y_ph, 'w': w_hmc, 'b': b_hmc, 'var_out': var_out_hmc})\n",
    "y_pred = tf.reduce_mean(model.get('out').distribution.mean, axis=0)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean((y_pred - y_ph)**2))\n",
    "\n",
    "hmc_T = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "traces = np.zeros([hmc_T, n_chain, n_covariates+1, 1])\n",
    "feed_dict = {x_ph: X, y_ph: Y}\n",
    "for i in range(hmc_T):\n",
    "    _, ws, bs, accr = sess.run(\n",
    "        [sample_op, hmc_info.samples['w'], hmc_info.samples['b'], hmc_info.acceptance_rate],\n",
    "        feed_dict)\n",
    "    traces[i] = np.concatenate([ws, bs.reshape((-1, 1, 1))], axis=1)\n",
    "    if i % 50 == 0:\n",
    "        print()\n",
    "        if i<100:\n",
    "            avg_w = traces[:i+1].mean(axis=0)\n",
    "        else:\n",
    "            avg_w = traces[100:i+1].mean(axis=0)\n",
    "        avg_w, avg_b = avg_w[:, :n_covariates], avg_w[:, -1].reshape((-1))\n",
    "        rmse = sess.run(test_rmse, {x_ph: X, y_ph: Y, w_hmc: avg_w, b_hmc: avg_b})\n",
    "    print('\\r Iter {} Acc.Rate {} RMSE {}'.format(\n",
    "        i, np.mean(accr), rmse), end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/zhusuan-dev/zhusuan/distributions/univariate.py:84: FutureWarning: Normal: The order of arguments logstd/std will change to std/logstd in the coming version.\n",
      "  \"to std/logstd in the coming version.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "n_svgd_particles = n_chain\n",
    "w_particles = tf.get_variable(\n",
    "    'w_svgd', [n_svgd_particles, n_covariates, 1], tf.float32, \n",
    "    tf.random_uniform_initializer(-1, 1))\n",
    "b_particles = tf.get_variable(\n",
    "    'b_svgd', [n_svgd_particles], tf.float32, \n",
    "    tf.zeros_initializer())\n",
    "var_out_particles = tf.get_variable(\n",
    "    'var_out_svgd', [n_svgd_particles], tf.float32,\n",
    "    tf.zeros_initializer())\n",
    "grad_and_vars = svgd.stein_variational_gradient(\n",
    "    log_joint, {'out': y_ph}, {\n",
    "        'w': w_particles,\n",
    "        'b': b_particles,\n",
    "        'var_out': var_out_particles\n",
    "    })\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "opt_op = optimizer.apply_gradients([(-g, v) for g, v in grad_and_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 RMSE [3.1447809]\n",
      "Iter 100 RMSE [1.3017794]\n",
      "Iter 200 RMSE [0.4363636]\n",
      "Iter 300 RMSE [0.15551053]\n",
      "Iter 400 RMSE [0.10132245]\n",
      "Iter 500 RMSE [0.09990899]\n",
      "Iter 600 RMSE [0.09986268]\n",
      "Iter 700 RMSE [0.09985027]\n",
      "Iter 800 RMSE [0.09984027]\n",
      "Iter 900 RMSE [0.09982991]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "SVGD_T = 1000\n",
    "for i in range(SVGD_T):\n",
    "    _ = sess.run([opt_op], feed_dict)\n",
    "    if i % 100 == 0:\n",
    "        fd = feed_dict.copy()\n",
    "        wp, bp, vp = sess.run([w_particles, b_particles, var_out_particles], fd)\n",
    "        fd.update({w_hmc: wp, b_hmc: bp, var_out_hmc: vp})\n",
    "        print('Iter {} RMSE {}'.format(i, sess.run([test_rmse], fd)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsdev",
   "language": "python",
   "name": "zsdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
