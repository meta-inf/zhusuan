{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zhusuan as zs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from zhusuan.variational import svgd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/zhusuan-dev/zhusuan/distributions/univariate.py:84: FutureWarning: Normal: The order of arguments logstd/std will change to std/logstd in the coming version.\n",
      "  \"to std/logstd in the coming version.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "n_covariates = 13\n",
    "\n",
    "n_dat, n_train = 600, 300\n",
    "w_true = np.random.normal(size=[n_covariates, 1])\n",
    "b_true = np.random.normal() * 0.5\n",
    "X = np.random.uniform(-2, 2, size=[n_dat, n_covariates])\n",
    "Y = np.squeeze((X + 0.1 * X ** 3) @ w_true) +\\\n",
    "    np.diag(X @ np.random.normal(size=[n_covariates, n_dat]) * 0.1) + b_true\n",
    "Y += np.random.normal(size=[n_dat]) * 0.1\n",
    "X, Xt = X[:n_train], X[n_train:]\n",
    "Y, Yt = Y[:n_train], Y[n_train:]\n",
    "# Y_prob = 1 / (1 + np.exp(-Y_logits))\n",
    "# Y = np.zeros((X.shape[0], ), dtype=np.int32)\n",
    "# Y[np.random.uniform(0, 1, size=[X.shape[0]]) < Y_prob] = 1\n",
    "\n",
    "@zs.reuse('linear_reg')\n",
    "def linear_regression(inp, observed):\n",
    "    with zs.BayesianNet(observed) as model:\n",
    "        w = zs.Normal(\n",
    "            'w', \n",
    "            mean=tf.zeros([n_covariates, 1]),\n",
    "            std=np.float32(1),\n",
    "            group_ndims=2)\n",
    "        b = zs.Normal(\n",
    "            'b', \n",
    "            mean=np.float32(0),\n",
    "            std=np.float32(1))\n",
    "        n_particles = tf.shape(w.tensor)[0]  # TODO: this assumes rank(w)==3. Does this hold when n_particles=1?\n",
    "        inp = tf.tile(tf.expand_dims(inp, 0), [n_particles, 1, 1])\n",
    "        # print(tf.squeeze(inp @ w, axis=-1).shape, b.tensor.shape)\n",
    "        mean = tf.squeeze(inp @ w, axis=-1) + tf.expand_dims(b, 1) # [n_particles, n_batch]\n",
    "        # print(logits.shape)\n",
    "        var_out = zs.Normal('var_out', mean=np.float32(0.1), std=np.float32(1))\n",
    "        std = tf.expand_dims(tf.nn.softplus(var_out), 1)\n",
    "        out = zs.Normal('out', mean, std, group_ndims=1) \n",
    "    return model\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32, [None, n_covariates])\n",
    "y_ph = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "def log_joint(observed):\n",
    "    model = linear_regression(x_ph, observed)\n",
    "    ret = tf.add_n(model.local_log_prob(['w', 'b', 'var_out', 'out']))\n",
    "    return ret\n",
    "\n",
    "hmc = zs.HMC(step_size=1e-2, n_leapfrogs=20, adapt_step_size=True,\n",
    "             target_acceptance_rate=0.6)\n",
    "n_chain = 10\n",
    "w_hmc = tf.Variable(tf.zeros([n_chain, n_covariates, 1]), name='w_hmc')\n",
    "b_hmc = tf.Variable(tf.zeros([n_chain]), name='b_hmc')\n",
    "var_out_hmc = tf.Variable(tf.zeros([n_chain]), name='var_out')\n",
    "sample_op, hmc_info = hmc.sample(\n",
    "    log_joint, observed={'out': y_ph}, \n",
    "    latent={'w': w_hmc, 'b': b_hmc, 'var_out': var_out_hmc})\n",
    "\n",
    "model = linear_regression(x_ph, {\n",
    "    'out': y_ph, 'w': w_hmc, 'b': b_hmc, 'var_out': var_out_hmc})\n",
    "y_pred = tf.reduce_mean(model.get('out').distribution.mean, axis=0)\n",
    "test_rmse = tf.sqrt(tf.reduce_mean((y_pred - y_ph)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iter 49 Acc.Rate 0.5636581182479858 RMSE 1.51702880859375\n",
      " Iter 99 Acc.Rate 0.7184661030769348 RMSE 0.6041986942291266\n",
      " Iter 149 Acc.Rate 0.6586695313453674 RMSE 0.5087842941284188\n",
      " Iter 199 Acc.Rate 0.5569800138473511 RMSE 0.5083652734756477\n",
      " Iter 249 Acc.Rate 0.47831469774246216 RMSE 0.508267343044281\n",
      " Iter 299 Acc.Rate 0.8362857103347778 RMSE 0.50872433185577399\n"
     ]
    }
   ],
   "source": [
    "hmc_T = 300\n",
    "sess.run(tf.global_variables_initializer())\n",
    "traces = np.zeros([hmc_T, n_chain, n_covariates+1, 1])\n",
    "feed_dict = {x_ph: X, y_ph: Y}\n",
    "for i in range(hmc_T):\n",
    "    _, ws, bs, accr = sess.run(\n",
    "        [sample_op, hmc_info.samples['w'], hmc_info.samples['b'], hmc_info.acceptance_rate],\n",
    "        feed_dict)\n",
    "    traces[i] = np.concatenate([ws, bs.reshape((-1, 1, 1))], axis=1)\n",
    "    if i % 50 == 0:\n",
    "        print()\n",
    "        if i<100:\n",
    "            avg_w = traces[:i+1].mean(axis=0)\n",
    "        else:\n",
    "            avg_w = traces[100:i+1].mean(axis=0)\n",
    "        avg_w, avg_b = avg_w[:, :n_covariates], avg_w[:, -1].reshape((-1))\n",
    "        rmse = sess.run(test_rmse, {x_ph: Xt, y_ph: Yt, w_hmc: avg_w, b_hmc: avg_b})\n",
    "    print('\\r Iter {} Acc.Rate {} RMSE {}'.format(\n",
    "        i, np.mean(accr), rmse), end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svgd(n_svgd_particles):\n",
    "    w_particles = tf.get_variable(\n",
    "        'w_svgd', [n_svgd_particles, n_covariates, 1], tf.float32, \n",
    "        tf.random_uniform_initializer(-1, 1))\n",
    "    b_particles = tf.get_variable(\n",
    "        'b_svgd', [n_svgd_particles], tf.float32, \n",
    "        tf.zeros_initializer())\n",
    "    var_out_particles = tf.get_variable(\n",
    "        'var_out_svgd', [n_svgd_particles], tf.float32,\n",
    "        tf.zeros_initializer())\n",
    "    grad_and_vars = svgd.stein_variational_gradient(\n",
    "        log_joint, {'out': y_ph}, {\n",
    "            'w': w_particles,\n",
    "            'b': b_particles,\n",
    "            'var_out': var_out_particles\n",
    "        })\n",
    "    optimizer = tf.train.AdamOptimizer(0.05)\n",
    "    opt_op = optimizer.apply_gradients([(-g, v) for g, v in grad_and_vars])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    SVGD_T = 1000\n",
    "    for i in range(SVGD_T):\n",
    "        _ = sess.run([opt_op], feed_dict)\n",
    "        if i % 100 == 0:\n",
    "            fd = {x_ph: Xt, y_ph: Yt}\n",
    "            wp, bp, vp = sess.run([w_particles, b_particles, var_out_particles], fd)\n",
    "            if n_svgd_particles != n_chain:\n",
    "                wp0 = np.zeros((n_chain, n_covariates, 1)).astype('f')\n",
    "                bp0 = np.zeros((n_chain,)).astype('f')\n",
    "                vp0 = np.zeros((n_chain,)).astype('f')\n",
    "                for i in range(0, n_chain, n_svgd_particles):\n",
    "                    wp0[i:i+n_svgd_particles] = wp\n",
    "                    bp0[i:i+n_svgd_particles] = bp\n",
    "                    vp0[i:i+n_svgd_particles] = vp\n",
    "                wp, bp, vp = wp0, bp0, vp0\n",
    "            fd.update({w_hmc: wp, b_hmc: bp, var_out_hmc: vp})\n",
    "            print('Iter {} RMSE {}'.format(i, sess.run([test_rmse], fd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/zhusuan-dev/zhusuan/distributions/univariate.py:84: FutureWarning: Normal: The order of arguments logstd/std will change to std/logstd in the coming version.\n",
      "  \"to std/logstd in the coming version.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 RMSE [3.4812257]\n",
      "Iter 100 RMSE [0.5099669]\n",
      "Iter 200 RMSE [0.5096439]\n",
      "Iter 300 RMSE [0.50967413]\n",
      "Iter 400 RMSE [0.50972116]\n",
      "Iter 500 RMSE [0.50975984]\n",
      "Iter 600 RMSE [0.509758]\n",
      "Iter 700 RMSE [0.5098064]\n",
      "Iter 800 RMSE [0.5096244]\n",
      "Iter 900 RMSE [0.5096958]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('v10'):\n",
    "    test_svgd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyu/zhusuan-dev/zhusuan/distributions/univariate.py:84: FutureWarning: Normal: The order of arguments logstd/std will change to std/logstd in the coming version.\n",
      "  \"to std/logstd in the coming version.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 8 RMSE [4.0294843]\n",
      "Iter 8 RMSE [0.5107512]\n",
      "Iter 8 RMSE [0.5097867]\n",
      "Iter 8 RMSE [0.50982356]\n",
      "Iter 8 RMSE [0.5097693]\n",
      "Iter 8 RMSE [0.50978273]\n",
      "Iter 8 RMSE [0.5097728]\n",
      "Iter 8 RMSE [0.50977445]\n",
      "Iter 8 RMSE [0.5097622]\n",
      "Iter 8 RMSE [0.5097647]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('v2'):\n",
    "    test_svgd(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsdev",
   "language": "python",
   "name": "zsdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
